# NLP_Project_Team_9
Sentiment analysis for Telugu text - classifying text as positive, negative or neutral.

# Telugu Sentiment Analysis

A comprehensive toolkit for analyzing sentiment in Telugu text, featuring traditional machine learning and deep learning approaches with extensive feature engineering.

## Overview

This project provides a complete pipeline for Telugu sentiment analysis, from data preprocessing to advanced modeling. It includes specialized techniques for Telugu text normalization, tokenization, and feature extraction, as well as implementations of both traditional machine learning models and neural networks for sentiment classification.

## Features

- Complete Telugu text preprocessing pipeline
- Extensive feature engineering including:
  - Linguistic features (POS tagging, word statistics)
  - Semantic features (word embeddings, sentiment lexicons)
  - Clustering-based features
- Multiple model implementations:
  - Traditional ML (Random Forest, Logistic Regression)
  - Neural Networks (Hybrid models, LSTM, Bidirectional LSTM)
- Comprehensive evaluation metrics and visualizations

## Configuration and Installation

### Prerequisites

- Python 3.8+
- CUDA-compatible GPU (recommended for neural network training)

### Installation

#### Google Colab (Recommended)

1. Upload the `Nlp_project_Final.ipynb` notebook to Google Colab
2. The notebook is designed to run in Google Colab with GPU acceleration
3. Required packages will be installed automatically through the notebook

#### Local System Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/Cha14ran/DREAM-T.git
   cd DREAM-T
   ```

2. Create a virtual environment (recommended):
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install the required packages:
   ```bash
   pip install indic-nlp-library advertools gensim stanza fasttext torch pandas numpy matplotlib seaborn scikit-learn xgboost imbalanced-learn wordcloud
   ```

4. Download external resources:
   ```bash
   # Clone Indic NLP resources
   git clone https://github.com/anoopkunchukuttan/indic_nlp_resources
   
   # Download FastText Telugu embeddings
   wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.te.300.bin.gz
   gunzip cc.te.300.bin.gz
   
   # Download Stanza Telugu model
   python -c "import stanza; stanza.download('te')"
   ```

### Required Packages

The following packages are required:

```
pandas>=1.1.0
numpy>=1.23.5
indic-nlp-library>=0.92
advertools>=0.16.6
gensim>=4.3.0
stanza>=1.10.0
fasttext>=0.9.2
scikit-learn>=1.0.0
matplotlib>=3.5.0
seaborn>=0.11.0
torch>=1.10.0
xgboost>=1.5.0
imbalanced-learn>=0.8.0
wordcloud>=1.8.0
```

## File Manifest

```
NLP_Project_Team_9/
├── Nlp_project_Final.ipynb # Main Jupyter notebook with the complete pipeline
├── pos.txt # Positive sentiment words list (Required Input)
├── neg.txt # Negative sentiment words list (Required Input)
├── processed_train_data.csv # Intermediate: Initial preprocessed data (Generated by notebook)
├── pos_tagging.csv # Intermediate: Data after POS tagging (Generated by notebook)
├── train_df_poscounts.csv # Intermediate: Data after sentiment lexicon features (Generated by notebook)
├── final_df.csv # Intermediate: Data after clustering features (Generated by notebook)
├── processed_train_df.csv # Intermediate: Final scaled numeric features for ML (Generated by notebook)
└── README.md

```

## Required External Files

The following files need to be downloaded separately:

## Required Input Files & Generated Files

### Required Input Files (Must be provided before running)

1.  **Positive and Negative Word Lists**:
    *   Files: `pos.txt`, `neg.txt`
    *   *Crucial*: These files must be present in the same directory as the notebook or uploaded to the Colab environment before execution.

### Handled by Notebook (Downloads/Clones Automatically)

The following resources are automatically downloaded or cloned by the `Nlp_project_Final.ipynb` notebook during execution. **You do not need to download these manually beforehand.**

1.  **Telugu Sentiment Dataset**:
    *   Source: [mounikaiiith/Telugu\_Sentiment](https://huggingface.co/datasets/mounikaiiith/Telugu_Sentiment/viewer)
    *   Files: `Sentiment_train.csv`, `Sentiment_valid.csv`, `Sentiment_test.csv`

2.  **FastText Telugu Embeddings**:
    *   File: `cc.te.300.bin` (from `cc.te.300.bin.gz`)
    *   Source: [Facebook FastText](https://fasttext.cc/docs/en/crawl-vectors.html)

3.  **Indic NLP Resources**:
    *   Repository: [indic\_nlp\_resources](https://github.com/anoopkunchukuttan/indic_nlp_resources)

4.  **Telugu Font** (Optional, for WordCloud visualization):
    *   File: `NotoSansTelugu-Regular.ttf`
    *   Source: [Google Noto Fonts](https://fonts.google.com/noto/specimen/Noto+Sans+Telugu)

5.  **Stanza Models**:
    *   Telugu language models for POS tagging.

### Generated Files (Created during notebook execution)
#### *(Unzip these files for execution) 

These intermediate and final data files are created by the `Nlp_project_Final.ipynb` notebook as it processes the data:

1.  `processed_train_data.csv`: Contains the initial preprocessed text data (after normalization, tokenization, stopword removal) along with sentence length.
2.  `pos_tagging.csv`: Includes the data after POS tagging has been applied and POS counts have been added.
3.  `train_df_poscounts.csv`: Contains data after sentiment lexicon features (pos/neg/neu counts, avg similarities based on FastText) have been calculated and added.
4.  `final_df.csv`: Includes data after clustering features (dominant cluster ratio, cluster entropy based on K-Means on FastText vectors) have been added.
5.  `processed_train_df.csv`: Contains the final set of scaled/normalized numeric features (derived from all previous feature engineering steps) used as input for the machine learning models.

*(Note: `indic_nlp_resources/`, `cc.te.300.bin`, and `NotoSansTelugu-Regular.ttf` are downloaded/cloned by the notebook itself and are not required as initial input files.)*

## Operating Instructions

### Running in Google Colab (Recommended)

1. Upload the `Nlp_project_Final.ipynb` notebook to Google Colab
2. Upload the required external files (`pos.txt`, `neg.txt`) to your Colab session
3. Run the cells in order, as the notebook will:
   - Install all required dependencies
   - Download the Telugu Sentiment dataset
   - Clone the Indic NLP resources
   - Download the FastText model
   - Process the data and train models

### Running Locally

1. Ensure all prerequisites and external files are in place
2. Set up the correct paths in the notebook:
   ```python
   # Update these paths for local execution
   os.environ['INDIC_RESOURCES_PATH'] = '/path/to/indic_nlp_resources'
   ```
3. Run the notebook cells in order

## Pipeline Workflow

The notebook implements the following workflow:

1. **Data Loading**: Load Telugu sentiment dataset from Hugging Face
2. **Text Preprocessing**:
   - Telugu script normalization
   - Tokenization
   - Stopword removal
3. **Feature Engineering**:
   - Basic statistical features (sentence length, word length)
   - Word embeddings using Word2Vec
   - POS tagging features
   - Sentiment lexicon features
   - Clustering features
4. **Model Training**:
   - Traditional ML models (Logistic Regression, Random Forest)
   - Neural network models (Hybrid NN, LSTM, Bidirectional LSTM)
5. **Model Evaluation**:
   - Classification metrics
   - Feature importance analysis

## Dataset Information

This project uses the Telugu Sentiment dataset available on Hugging Face:

- **Dataset**: [mounikaiiith/Telugu_Sentiment](https://huggingface.co/datasets/mounikaiiith/Telugu_Sentiment/viewer)
- **Description**: A collection of Telugu sentences labeled with sentiment (positive, negative, or neutral)
- **Files**:
  - `Sentiment_train.csv`: Training data
  - `Sentiment_valid.csv`: Validation data
  - `Sentiment_test.csv`: Test data

## Known Issues and Limitations

1. **Class Imbalance**: The dataset has an imbalanced distribution of sentiment classes, with neutral samples being overrepresented. This may affect model performance.

2. **Processing Time**: Feature extraction, particularly POS tagging and sentiment lexicon matching, can be time-consuming for large datasets.

3. **Memory Usage**: Loading and processing word embeddings requires significant memory, especially for the FastText model.

4. **Telugu Script Variations**: Some Telugu script variations may not be properly normalized, potentially affecting tokenization quality.

5. **Numpy Version Compatibility**: The notebook requires numpy==1.23.5 for compatibility with gensim. This may cause conflicts with other packages that require newer numpy versions.

## Troubleshooting

### Common Issues

1. **Missing Dependencies**:
   ```
   ModuleNotFoundError: No module named 'indic_nlp_library'
   ```
   **Solution**: Ensure all dependencies are installed using the installation commands provided.

2. **CUDA Out of Memory**:
   ```
   RuntimeError: CUDA out of memory
   ```
   **Solution**: Reduce batch size in the neural network training configuration or use a smaller model.

3. **Indic NLP Resources Path Error**:
   ```
   FileNotFoundError: [Errno 2] No such file or directory: '/content/indic_nlp_resources'
   ```
   **Solution**: Set the correct path to the Indic NLP resources directory:
   ```python
   import os
   os.environ['INDIC_RESOURCES_PATH'] = '/path/to/indic_nlp_resources'
   ```

4. **FastText Model Loading Error**:
   ```
   ValueError: fasttext_model: cannot open file
   ```
   **Solution**: Ensure the FastText model file (`cc.te.300.bin`) is in the correct location and has the correct permissions.

5. **Numpy Version Conflicts**:
   ```
   ERROR: pip's dependency resolver does not currently take into account all the packages that are installed
   ```
   **Solution**: In Colab, this warning can be ignored. For local installation, consider using a dedicated virtual environment.

### Performance Optimization

1. **Slow POS Tagging**: 
   - Use batch processing for POS tagging
   - Cache POS tags for frequently used words

2. **Memory Issues with Word Embeddings**:
   - Use dimensionality reduction techniques like PCA
   - Load only required word vectors instead of the entire model

3. **Slow Neural Network Training**:
   - Use mixed precision training
   - Implement early stopping
   - Use a smaller subset of features

## Copyright and Licensing

This project is based on the [DREAM-T repository](https://github.com/Cha14ran/DREAM-T) and follows its licensing terms.

The Telugu Sentiment dataset is provided under its original license. Please refer to the [dataset page](https://huggingface.co/datasets/mounikaiiith/Telugu_Sentiment) for more information.

## Contact Information

For questions or issues related to this project, please contact the repository owners:
- John Salvin (142503002@smail.iitpkd.ac.in)
- Sai Punith (142201021@smail.iitpkd.ac.in)
- Dadi Rishitha (142201005@smail.iitpkd.ac.in) 

## Credits and Acknowledgments

- **Telugu Sentiment Dataset**: [Mounika IIITH](https://huggingface.co/datasets/mounikaiiith/Telugu_Sentiment)
- **Indic NLP Library**: [Anoop Kunchukuttan](https://github.com/anoopkunchukuttan/indic_nlp_library)
- **FastText**: [Facebook Research](https://fasttext.cc/)
- **Stanza**: [Stanford NLP Group](https://stanfordnlp.github.io/stanza/)
- **DREAM-T Repository**: [Cha14ran](https://github.com/Cha14ran/DREAM-T)

Special thanks to the open-source community for providing tools and resources for Telugu NLP research.

## References

1. B. Sunitha and K. Madhavi. "Telugu Sentiwordnet: A lexical resource for sentiment analysis in Telugu." In 2018 Second International Conference on Computing Methodologies and Communication (ICCMC), pp. 659-663. IEEE, 2018.

2. R. S. Reddy and A. J. Reddy. "A hybrid approach for Telugu sentiment analysis." In Proceedings of the International Conference on Intelligent Computing and Control Systems (ICICCS), pp. 593-598. IEEE, 2018.

3. Kunchukuttan, A., Mehta, P., & Bhattacharyya, P. (2018). The IIT Bombay English-Hindi Parallel Corpus. In Proceedings of LREC 2018.

4. Cha14ran. (2023). DREAM-T: Deep Learning Resources for the Evaluation and Analysis of Multilingual Text. GitHub repository. https://github.com/Cha14ran/DREAM-T


